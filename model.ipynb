{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPbZZQHgSDI0a6ERqWenlYQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LucasLU-ZY/dlaicourse/blob/master/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeqvE9UT2prp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import math\n",
        "from tensorflow.keras import layers, Sequential\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOH5Y19e7iYp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BEST_MODEL_PATH_TEST = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOcUGfqp4Zn2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Evaluate(tf.keras.callbacks.Callback):\n",
        "    '''\n",
        "    Save the model if it is better after each epoch\n",
        "    '''\n",
        "\n",
        "    def __init__(self, model):\n",
        "        '''\n",
        "        Initialization\n",
        "            :param model:\n",
        "                Model that we are training\n",
        "        '''\n",
        "        super().__init__()\n",
        "        # Initialize the loss with a big value\n",
        "        self.lowest = 1e10\n",
        "        self.model = model\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        '''\n",
        "        Override function on_epoch_end to do the save job after an epoch,\n",
        "        if loss is lower than save the model\n",
        "            :param epoch:\n",
        "                The epoch we are now\n",
        "            :param logs:\n",
        "                The information in this epoch\n",
        "            :return:\n",
        "                None\n",
        "        '''\n",
        "        if logs['loss'] <= self.lowest:\n",
        "            self.lowest = logs['loss']\n",
        "            self.model.save(BEST_MODEL_PATH_TEST)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkEzeFIT4hcZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BasicBlock(layers.Layer):\n",
        "    '''\n",
        "    Create a basic residual network\n",
        "    '''\n",
        "    def __init__(self, filter_num, stride = (1, 1)):\n",
        "        super(BasicBlock, self).__init__()\n",
        "\n",
        "        self.conv1 = layers.Conv2D(filter_num, kernel_size=(3, 3), strides=stride, padding='same')\n",
        "        self.bn1 = layers.BatchNormalization()\n",
        "        self.relu = layers.Activation('relu')\n",
        "\n",
        "        self.conv2 = layers.Conv2D(filter_num, kernel_size=(3, 3), strides=(1, 1), padding='same')\n",
        "        self.bn2 = layers.BatchNormalization()\n",
        "        if stride != (1, 1):\n",
        "            # if stride is not 1, we use down sampling\n",
        "            self.downsample = Sequential()\n",
        "            self.downsample.add(layers.Conv2D(filter_num, kernel_size=(1, 1), strides=stride))\n",
        "        else:\n",
        "            self.downsample = lambda x: x\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        '''\n",
        "        Overwrite function call, when the class is called, execute this function to create the Basic Block\n",
        "            :param inputs:\n",
        "                Source of inputs\n",
        "            :param training:\n",
        "                If Training\n",
        "            :return:\n",
        "                Output of the Basic Block\n",
        "        '''\n",
        "        # [b, h, w, c]\n",
        "        # Connect all the layers of Basic Block\n",
        "        out = self.conv1(inputs)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = layers.Activation(\"relu\")(out)\n",
        "        identity = self.downsample(inputs)\n",
        "\n",
        "        output = layers.add([out, identity])\n",
        "\n",
        "        return output"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPhVf0Kh4kwu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResNet(tf.keras.Model):\n",
        "    '''\n",
        "    Create a Residual NetWork\n",
        "    '''\n",
        "    def __init__(self, layer_dims, num_classes=4):\n",
        "        '''\n",
        "        Initialize the Residual NetWork\n",
        "            :param layer_dims:\n",
        "                list of shape (1, 4) represent 4 dimensons of residual block\n",
        "            :param num_classes:\n",
        "                Number of classes to be classified\n",
        "        '''\n",
        "        super(ResNet, self).__init__()\n",
        "\n",
        "        self.stem = Sequential([layers.Conv2D(64, (3, 3), strides=(1, 1)),\n",
        "                                layers.BatchNormalization(),\n",
        "                                layers.Activation('relu'),\n",
        "                                layers.MaxPool2D(pool_size=(2, 2), strides=(1, 1), padding='same')\n",
        "        ])\n",
        "        self.layer1 = self.build_resblock(32, layer_dims[0])\n",
        "        self.layer2 = self.build_resblock(64, layer_dims[1])\n",
        "        self.layer3 = self.build_resblock(128, layer_dims[2])\n",
        "        self.layer4 = self.build_resblock(256, layer_dims[3])\n",
        "\n",
        "        self.drop = layers.Dropout(0.25)\n",
        "        self.avgpool = layers.GlobalAveragePooling2D()\n",
        "        self.flatten = layers.Flatten()\n",
        "        self.fc = layers.Dense(num_classes, activation=\"softmax\")\n",
        "\n",
        "    def call(self, inputs, training=None, mask=None):\n",
        "        '''\n",
        "        Overwrite function call, when the class is called, execute this function to create the Residual Block\n",
        "            :param inputs:\n",
        "                Source of inputs\n",
        "            :param training:\n",
        "                If Training\n",
        "            :param mask:\n",
        "                We don't use this here\n",
        "            :return:\n",
        "                Output of the Basic Block\n",
        "        :return:\n",
        "        '''\n",
        "        x = self.stem(inputs)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.drop(x)\n",
        "        # [b, c]\n",
        "        x = self.avgpool(x)\n",
        "        # [b, 100]\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def build_resblock(self, filter_num, blocks, stride=1):\n",
        "        '''\n",
        "        A function to build Residual Block\n",
        "            :param filter_num:\n",
        "                Filter number of Basic Block\n",
        "            :param blocks:\n",
        "                Number of blocks we will create\n",
        "            :param stride:\n",
        "                Identify the stride of each Basic Block\n",
        "            :return:\n",
        "                Residual Block\n",
        "        '''\n",
        "        res_block = Sequential()\n",
        "        # may down sample\n",
        "        res_block.add(BasicBlock(filter_num, stride))\n",
        "\n",
        "        for _ in range(1, blocks):\n",
        "            res_block.add(BasicBlock(filter_num, 1))\n",
        "        return res_block"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JD3FZvN84q51",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet18():\n",
        "    # Create ResNet 18\n",
        "    return ResNet([2, 2, 2, 2])\n",
        "\n",
        "def resnet34():\n",
        "    # Create ResNet 34\n",
        "    return ResNet([3, 4, 6, 3])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfbGWPmM44V0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}